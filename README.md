# DLS_1_Project

Сделано: 1 и 2 основные задания. 
На большее не хватило времени – загруженное начало года – скорее всего я тут совсем не одинок, а наоборот.
(Согласен, это не открытие, времени всегда не хватает, особенно бесплатного времени на GPU на google.colab.)

Выполнение первого задания представлено 5 блокнотами с номерами: 1.1, 1.2, 1.3, 1.4 и 1.5.
Выполнение второго задания представлено 2 блокнотами с номерами 2.1 и 2.2.

Все блокноты размещены здесь на GitHub.

Также на GitHub размещены все .csv файлы, созданные в результате исполнения этих блокнотов. 
А именно:
-	selected_celeba.csv (10000 выбранных изображений)
-	train_celeba.csv (8000 из 10000 изображений – train выборка)
-	val_celeba.csv (2000 из 10000 изображений – val выборка)
-	cropped_landmarks_celeba.csv (landmarks для изображений вырезанных лиц в папке Cropped)
-	val_report_celeba_ce_loss.csv (результат распознавания val выборки моделью из блокнота 2.1)
-	val_report_celeba_arcface_loss.csv (результат распознавания val выборки моделью из блокнота 2.2)

Тяжелые файлы на GitHub не загружал, они доступны только в моём Google Drive (ссылка ниже).
А именно:
-	Папка Selected. Содержит отобранные 10000 изображений (без физического разделения на train/val, которое я храню только в .csv файлах).
-	Папка Cropped. Содержит вырезанные 10000 изображений лиц до выполнения выравнивания.
-	Папка Aligned_2. Содержит 10000 изображений лиц, выравненных только по глазам (2 точки).
-	Папка Aligned_3. Содержит 10000 изображений лиц, выравненных по глазам и носу (3 точки).
-	Файл model_params_stackedhourglass.pt. Выгруженные параметры модели StackedHourglass.
-	Файл model_params_resnet18_ce_loss.pt. Выгруженные параметры модели ResNet18 (с моим fc) для блокнота 2.1. 
-	Файл model_params_resnet18_arcface_loss.pt. Выгруженные параметры модели ResNet18 (с моим fc) для блокнота 2.2.

Комментарии к блокнотам:

Задание 1.
- 1.1. Images subset selection.ipynb. Выбирает 500х20=10000 изображений (500 персон, ровно по 20 на персону). Переделывал 2 раза. Только лучший выбор этих 10000 позволил достичь качества в 70%. После первоначального выбора, который сначала показался очень рациональным, еле-еле дотянул до 50%. После второй попытки выборки – до 60%. И только с третьей попытки выбора 10000 смог достичь 70%. Сейчас бы еще раз переделал, добавил бы дополнительные критерии – может и 80% получилось бы достичь, ничего больше не изменяя.
- 1.2. Bboxes, landmarks & heatmaps visualization.ipynb. Здесь я тренируюсь и визуализирую, на отдельных случайных изображениях. Ничего не сохраняю, но проверяю алгоритмы.
- 1.3. Crop, resize & transform the selected subset.ipynb. Вырезает лица из 10000 изображений в папке Selected, сохраняет изображения 10000 лиц в папке Cropped, а landmarks для этих лиц сохраняет в файле cropped_landmarks_celeba.csv.
- 1.4. Dataset & Stacked Hourglass network. Строит и обучает модель StackedHourglass предсказывать 5 ключевых точек лица, на данных с предыдущего шага (блокнот 1.3).
- 1.5. Affine transform.ipynb. Выравнивает лица двумя способами (по 2 точкам и по 3 точкам). Сохраняет выравненные лица в папки Aligned_2 и Aligned_3 соответственно. При обучении моделей «Задания 2» лучший результат удалось получать при обучении на изображениях лиц, выравненных только по глазам (по двум точкам). Связываю это с всё ещё недостаточно качественным выбором 10000 изображений, т.к. отобрал в т.ч. и такие, которые сильно искажались при выполнении аффинного преобразования по 3-м точкам.

Задание 2.
- 2.1. CE Loss. Все комментарии в блокноте.
- 2.2. ArcFace Loss. Все комментарии в блокноте.

Сравнение CE Loss и ArcFace Loss: 
Первая обучается быстрее и стабильнее, вторая, за счет группировки embedding-ов, позволила достичь более высокой точности распознавания.

Общий вывод от реализованных заданий:
Качество данных имеет критическое значение.

Ссылка на папку проекта на моём Google Drive: https://drive.google.com/drive/folders/1mNpfxZ27d6zhN0FLA1d1f2dLhMGTIZlf?usp=sharing

Мой Telegram на всякий случай: https://t.me/dearkle
